{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inaugural Similarity Analysis\n",
    "1. Implement TF-IDF from scratch and use it to find the closest historic inaugural address to the 2017 address by President Trump\n",
    "2. Use Latent Symantec Indexing to identify an Inaugural most similar to a user-defined query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import inaugural\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize stemmer and lemmatizer\n",
    "porter    = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "wnl       = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first 4 items of the inaugural datasets\n",
    "inaugural.fileids()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the tokenized words from the first inaugural \n",
    "inaugural.words(inaugural.fileids()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Stopwords\n",
    "\n",
    "**Update stopwords**\n",
    "\n",
    "Remove all punctuation and strange unicode characters, and anything else that might be extraneous. However, the updated list of stopwords is not exaustive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update stopwords\n",
    "stop_words.update(['-', ',', '.', '!', '?', ' ', ':', ';', '/', '[', ']', \n",
    "                   '*', '\"', '(', ')', '#', '$', '%', '&', '~', '@', '<', '>',\n",
    "                  '{', '}', '^', '--', \"'\", '.\"', '14th', '\";', '\"?', '),', '...', \n",
    "                   '¡¦', '¡§', '¡¨¡', ',\"', '.)', '....', '\\x80\\x94', '¡', '.¡¨'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Read each inaugural address into an Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Create a vocabulary as a set of all unique stemmed terms in the corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an empty set to store vocabs\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code for creating the vocab goes here\n",
    "temp_list = [wnl.lemmatize(porter.stem(w.lower())) for w in inaugural.words() if w.lower() not in stop_words]\n",
    "vocab = set(sorted(temp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  5399  unique words in our corpus.\n"
     ]
    }
   ],
   "source": [
    "# check out vocab length\n",
    "print('there are ', len(vocab), ' unique words in our corpus.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Use ocabulary to read each inaugural address into a dataframe**\n",
    "\n",
    "Each row of the dataframe represents a document (one of the addresses), each column of the dataframe is a term from the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 5399)\n"
     ]
    }
   ],
   "source": [
    "# initiate a dictionary for tracking document size\n",
    "doc_length = {}\n",
    "# initiate an empty dataframe\n",
    "df = pd.DataFrame()\n",
    "# loop through all documents in corpus\n",
    "for fileid in inaugural.fileids():\n",
    "    # populate doc_length\n",
    "    doc_length[fileid] = len(inaugural.words(fileid))\n",
    "    # create a temporary dictionary for each document for tracking word frequency\n",
    "    temp_list = [wnl.lemmatize(porter.stem(w.lower())) for w in inaugural.words(fileid) \n",
    "                 if w.lower() not in stop_words]\n",
    "    temp_dict = dict(FreqDist(sorted(temp_list)))\n",
    "    # covert dictionary to series and add to dataframe\n",
    "    df = df.append(pd.Series(temp_dict, name = fileid))\n",
    "    pass\n",
    "# fill null value\n",
    "df.fillna(0, inplace = True)\n",
    "# check df size\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Compute TF-IDF for the document-term matrix ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1. Write a function to compute term frequency (TF) for each document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute term frequency\n",
    "# inputs: wordvec is a series that contains, for a given doc, \n",
    "#                 the word counts for each term in the vocab\n",
    "#         doclen  is the length of the document\n",
    "# returns: a series with new term-frequencies (raw counts divided by doc length)\n",
    "def computetf(wordvec,doclen):\n",
    "    return wordvec/doclen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Write a function to comput inverse document frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# input:   document-by-term (row-by-column) dataframe\n",
    "# returns: dictionary of key-value pairs. Keys are terms in the vocab, values are IDF.\n",
    "def computeidf(df):\n",
    "    idf_dict = {}\n",
    "    for vocab in df.columns.values:\n",
    "        # calculate the ratio of total number of documents over number of documents\n",
    "        # containing current vocab, and tkae a log of this ratio.\n",
    "        ratio = df.shape[0] / (df[vocab] > 0).sum()\n",
    "        idf_dict[vocab] = math.log(ratio)\n",
    "        pass\n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a new dataframe and populate it with the TF-IDF values for each document-term combination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a new dataframe that stores TF-IDF values\n",
    "newdf = pd.DataFrame()\n",
    "# compute idf\n",
    "idfdict = computeidf(df)\n",
    "# compute tf-idf\n",
    "cols = df.columns\n",
    "for index, row in df.iterrows():\n",
    "    newrow = computetf(row,doc_length[index])\n",
    "    for c in cols:\n",
    "        newrow[c] = newrow[c]*idfdict[c]\n",
    "    newdf = newdf.append(newrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (58, 5399)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of tf-idf dataframe\n",
    "print('shape: ', newdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>1</th>\n",
       "      <th>100</th>\n",
       "      <th>120</th>\n",
       "      <th>125</th>\n",
       "      <th>13</th>\n",
       "      <th>15th</th>\n",
       "      <th>16</th>\n",
       "      <th>1774</th>\n",
       "      <th>1776</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>yorktown</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealou</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789-Washington.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793-Washington.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797-Adams.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801-Jefferson.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805-Jefferson.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     000    1  100  120  125   13  15th   16  1774  1776  ...  \\\n",
       "1789-Washington.txt  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0   0.0  ...   \n",
       "1793-Washington.txt  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0   0.0  ...   \n",
       "1797-Adams.txt       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0   0.0  ...   \n",
       "1801-Jefferson.txt   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0   0.0  ...   \n",
       "1805-Jefferson.txt   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0   0.0  ...   \n",
       "\n",
       "                     york  yorktown  young  younger  youngest  youth  \\\n",
       "1789-Washington.txt   0.0       0.0    0.0      0.0       0.0    0.0   \n",
       "1793-Washington.txt   0.0       0.0    0.0      0.0       0.0    0.0   \n",
       "1797-Adams.txt        0.0       0.0    0.0      0.0       0.0    0.0   \n",
       "1801-Jefferson.txt    0.0       0.0    0.0      0.0       0.0    0.0   \n",
       "1805-Jefferson.txt    0.0       0.0    0.0      0.0       0.0    0.0   \n",
       "\n",
       "                         zeal  zealou  zealous  zone  \n",
       "1789-Washington.txt  0.000000     0.0      0.0   0.0  \n",
       "1793-Washington.txt  0.000000     0.0      0.0   0.0  \n",
       "1797-Adams.txt       0.000766     0.0      0.0   0.0  \n",
       "1801-Jefferson.txt   0.001024     0.0      0.0   0.0  \n",
       "1805-Jefferson.txt   0.002493     0.0      0.0   0.0  \n",
       "\n",
       "[5 rows x 5399 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the first 5 rows of the tf-idf dataframe\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. Using TF-IDF values, find and rank order the 3 closest inaugural addresses to Donald Trump's 2017 address, measured by cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000        0.0\n",
       "1          0.0\n",
       "100        0.0\n",
       "120        0.0\n",
       "125        0.0\n",
       "          ... \n",
       "youth      0.0\n",
       "zeal       0.0\n",
       "zealou     0.0\n",
       "zealous    0.0\n",
       "zone       0.0\n",
       "Name: 2017-Trump.txt, Length: 5399, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# President Trump's address is 57 (0-indexed)\n",
    "newdf.iloc[57,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 Create an array called dist that contains the cosine similarity distance between the 2017 inaugural address and each of the inaugural addresses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# assign PResident Trump's tf_idf values to d1\n",
    "d1 = newdf.iloc[57,:]\n",
    "# find its magnitude \n",
    "norm_d1 = np.sqrt(np.sum(np.square(d1)))\n",
    "# create a list for storing cosine similarities between each inaugural and President Trump\n",
    "dist = []\n",
    "for index,row in newdf.iterrows():\n",
    "    temp_norm = np.sqrt(np.sum(np.square(row)))\n",
    "    cos_sim = np.dot(d1, row) / (norm_d1 * temp_norm)\n",
    "    dist.append(cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Find the 3 closest associated inaugural address, when measured by cosign similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1969-Nixon.txt', '1997-Clinton.txt', '1993-Clinton.txt'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find 3 inaugurals that are most similar to Trump. \n",
    "indices = np.array(dist).argsort()[-4:-1]\n",
    "df.index[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity is often used in text classification to measure the textual content similarity of two documents. This is normally calculated based on word frequencies relative to the entire corpus, which can be meaninfully represented using TF-IDF.\n",
    "\n",
    "In this case, inaugural A is considered 'close' to inaugural B if the words used and frequencies of each word used are relatively similar than the ones between inaugural A and inaugural B. As illustrated in the code snippets below, the first dataframe dipicts the words that appeared more than 5 times in Trump's inaugural and also appeared at least once in the 3 closest associated inaugural address. We could see that these words such as 'america', 'great', 'people', 'nation' were also frequently used by the other 3 presidents.\n",
    "\n",
    "In contrast, the second dataframe shows the 3 furtherest assocaited inaugural address, where such pattern is pattern is not observed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>american</th>\n",
       "      <th>great</th>\n",
       "      <th>nation</th>\n",
       "      <th>new</th>\n",
       "      <th>one</th>\n",
       "      <th>peopl</th>\n",
       "      <th>presid</th>\n",
       "      <th>world</th>\n",
       "      <th>america</th>\n",
       "      <th>make</th>\n",
       "      <th>god</th>\n",
       "      <th>across</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1969-Nixon.txt</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-Clinton.txt</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-Clinton.txt</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-Trump.txt</th>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  american  great  nation   new   one  peopl  presid  world  \\\n",
       "1969-Nixon.txt         4.0    7.0     9.0   8.0   7.0   15.0     3.0   15.0   \n",
       "1997-Clinton.txt      16.0    6.0    15.0  29.0  10.0   11.0     1.0   15.0   \n",
       "1993-Clinton.txt      14.0    2.0     5.0   9.0   1.0   12.0     3.0   20.0   \n",
       "2017-Trump.txt        15.0    6.0    13.0   6.0   9.0   10.0     5.0    6.0   \n",
       "\n",
       "                  america  make  god  across  today  \n",
       "1969-Nixon.txt        6.0  10.0  6.0     1.0    5.0  \n",
       "1997-Clinton.txt     15.0   5.0  1.0     2.0    6.0  \n",
       "1993-Clinton.txt     19.0   3.0  2.0     4.0   10.0  \n",
       "2017-Trump.txt       20.0   6.0  5.0     5.0    5.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find words that appear in all 4 inaugurals and appears at least 5 times in Trump's inaugural\n",
    "similar_df = df.loc[['1969-Nixon.txt', '1997-Clinton.txt', '1993-Clinton.txt', '2017-Trump.txt'], :]\n",
    "keywords = [w for w in similar_df.columns if (similar_df[w]>0).sum() >= 4 and similar_df.loc['2017-Trump.txt', w] >= 5]\n",
    "similar_df[keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1789-Washington.txt', '1809-Madison.txt', '1829-Jackson.txt'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find 3 inaugurals that are most different from Trump. \n",
    "df.index[np.array(dist).argsort()[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countri</th>\n",
       "      <th>everi</th>\n",
       "      <th>nation</th>\n",
       "      <th>never</th>\n",
       "      <th>peopl</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789-Washington.txt</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809-Madison.txt</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829-Jackson.txt</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-Trump.txt</th>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     countri  everi  nation  never  peopl  right\n",
       "1789-Washington.txt      5.0    9.0     4.0    2.0    4.0    2.0\n",
       "1809-Madison.txt         5.0    2.0    10.0    1.0    1.0    5.0\n",
       "1829-Jackson.txt         2.0    1.0     6.0    1.0    4.0    4.0\n",
       "2017-Trump.txt          12.0    7.0    13.0    6.0   10.0    5.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find words that appear in all 4 inaugurals and appears at least 5 times in Trump's inaugural\n",
    "diff_df = df.loc[['1789-Washington.txt', '1809-Madison.txt', '1829-Jackson.txt', '2017-Trump.txt'], :]\n",
    "keywords = [w for w in diff_df.columns if (diff_df[w]>0).sum() >= 4 and diff_df.loc['2017-Trump.txt', w] >= 5]\n",
    "diff_df[keywords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. Transform the original inaugural addresses using TfidfVectorizer from scikit-learn\n",
    "**5.1 Create a new dataframe for storing inaugural addresses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "for fileid in inaugural.fileids():\n",
    "    new_df = new_df.append({'name':fileid, 'doc':inaugural.raw(fileid)}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 define a tokenizer to lemmatize and stem tokenized words within TfidfVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.stem import PorterStemmer\n",
    "\n",
    "class word_processor:\n",
    "    def __init__(self):\n",
    "        self.porter = porter\n",
    "        self.wnl = wnl\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(self.porter.stem(t)) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"''\", \"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", '``', 'abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'ha', 'hi', 'might', 'must', \"n't\", 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'thi', 'veri', 'wa', 'whi', 'wo', 'would', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of transformed docs:  (58, 5574)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(use_idf = True, \n",
    "                            tokenizer = word_processor(), \n",
    "                            lowercase = True, \n",
    "                            stop_words = stop_words)\n",
    "\n",
    "X = tfidf_vec.fit_transform(new_df['doc'])\n",
    "print('shape of transformed docs: ',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Compute the truncated SVD\n",
    "**6.1 compute singular vectors and singular valuses using SVD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=5, n_iter=10, random_state=44)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import library\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# call a TruncatedSVD class\n",
    "svd = TruncatedSVD(n_components = 5, n_iter = 10, random_state = 44)\n",
    "svd.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of U:  (58, 5)\n",
      "shape of sigma (singular values):  (5,)\n",
      "shape of V transposed:  (5, 5574)\n"
     ]
    }
   ],
   "source": [
    "# calculate singular vectors and sigular values:\n",
    "U = svd.fit_transform(X) / svd.singular_values_\n",
    "S = svd.singular_values_\n",
    "VT = svd.components_\n",
    "\n",
    "print('shape of U: ', U.shape)\n",
    "print('shape of sigma (singular values): ', S.shape)\n",
    "print('shape of V transposed: ', VT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.2 Visualize sigm aby Looking at $\\sigma_i, i=1,\\ldots,k$. The singular values $\\sigma_i$ diminishes as $k$ increases.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (7,7))\n",
    "plt.plot([x for x in range(1,len(S)+1)], S, 'bo')\n",
    "plt.xticks(ticks = [1, 2, 3, 4, 5], labels = [1, 2, 3, 4, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.3 for each singular vector (feature vector), find the index of the 5 largest terms, and extract the corresponding terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['ha', 'peopl', 'govern', 'nation', 'thi']\n",
      "1 ['new', \"'s\", 'world', 'u', 'america']\n",
      "2 ['peopl', 'econom', 'busi', 'law', 'upon']\n",
      "3 ['counsel', 'success', 'peac', 'war', 'nation']\n",
      "4 ['ani', 'offens', 'union', 'war', 'shall']\n"
     ]
    }
   ],
   "source": [
    "terms = tfidf_vec.get_feature_names()\n",
    "for k in range(5):\n",
    "    print(k, [terms[i] for i in VT[k].argsort()[-5:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 7. Inaugural Similarity on user-defined query\n",
    "**7.1 Get and transform user query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter a sentence:  peace and prosperity and love and care\n"
     ]
    }
   ],
   "source": [
    "# get user input\n",
    "query = input('Please enter a sentence: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You entered:  peace and prosperity and love and care \n",
      "\n",
      "  (0, 3779)\t0.47196368319888016\n",
      "  (0, 3500)\t0.41054832177184714\n",
      "  (0, 2936)\t0.5463965610047704\n",
      "  (0, 754)\t0.5569121612551006\n"
     ]
    }
   ],
   "source": [
    "print('You entered: ', query, '\\n')\n",
    "# transfrom user query and display its tf-idf values\n",
    "query_xform = tfidf_vec.transform([query])\n",
    "print(query_xform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.2 Project the transformed query into the document-by-feature space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of query in document-by-feature space:  (1, 5)\n",
      "feature embedding of the query:  [[ 0.02073696  0.00746746  0.00702104  0.0178147  -0.01463502]]\n"
     ]
    }
   ],
   "source": [
    "# convert sigma from vector into a matrix and invert it\n",
    "S_values = np.linalg.inv(np.diag(S))\n",
    "# multiple V by s_values\n",
    "Z = np.matmul(np.transpose(VT),S_values)\n",
    "# multiple transformed query and Z\n",
    "query_feature = np.matmul(query_xform.toarray(), Z)\n",
    "print('shape of query in document-by-feature space: ', query_feature.shape)\n",
    "# display features used to represent query\n",
    "print('feature embedding of the query: ', query_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1789-Washington.txt [[0.3962494]]\n",
      "1793-Washington.txt [[-0.65416742]]\n",
      "1797-Adams.txt [[0.64309032]]\n",
      "1801-Jefferson.txt [[0.44674683]]\n",
      "1805-Jefferson.txt [[0.5187397]]\n",
      "1809-Madison.txt [[0.7041189]]\n",
      "1813-Madison.txt [[0.61570922]]\n",
      "1817-Monroe.txt [[0.48549318]]\n",
      "1821-Monroe.txt [[0.42035131]]\n",
      "1825-Adams.txt [[0.42208722]]\n",
      "1829-Jackson.txt [[0.41099476]]\n",
      "1833-Jackson.txt [[-0.03719566]]\n",
      "1837-VanBuren.txt [[0.56534884]]\n",
      "1841-Harrison.txt [[0.00941384]]\n",
      "1845-Polk.txt [[-0.07826999]]\n",
      "1849-Taylor.txt [[-0.21271954]]\n",
      "1853-Pierce.txt [[0.37856621]]\n",
      "1857-Buchanan.txt [[-0.18095897]]\n",
      "1861-Lincoln.txt [[-0.43871353]]\n",
      "1865-Lincoln.txt [[-0.21272667]]\n",
      "1869-Grant.txt [[0.07931181]]\n",
      "1873-Grant.txt [[0.22063421]]\n",
      "1877-Hayes.txt [[0.18575765]]\n",
      "1881-Garfield.txt [[-0.2123006]]\n",
      "1885-Cleveland.txt [[0.0410068]]\n",
      "1889-Harrison.txt [[-0.07613883]]\n",
      "1893-Cleveland.txt [[0.32823755]]\n",
      "1897-McKinley.txt [[0.12126114]]\n",
      "1901-McKinley.txt [[0.28575667]]\n",
      "1905-Roosevelt.txt [[0.87690435]]\n",
      "1909-Taft.txt [[-0.04408204]]\n",
      "1913-Wilson.txt [[0.53567608]]\n",
      "1917-Wilson.txt [[0.6794909]]\n",
      "1921-Harding.txt [[0.68848673]]\n",
      "1925-Coolidge.txt [[0.69523681]]\n",
      "1929-Hoover.txt [[0.46647161]]\n",
      "1933-Roosevelt.txt [[0.66578166]]\n",
      "1937-Roosevelt.txt [[0.59463371]]\n",
      "1941-Roosevelt.txt [[0.88794641]]\n",
      "1945-Roosevelt.txt [[-0.12751928]]\n",
      "1949-Truman.txt [[0.74596643]]\n",
      "1953-Eisenhower.txt [[0.55857491]]\n",
      "1957-Eisenhower.txt [[0.59413758]]\n",
      "1961-Kennedy.txt [[0.12660046]]\n",
      "1965-Johnson.txt [[0.12005961]]\n",
      "1969-Nixon.txt [[0.13492419]]\n",
      "1973-Nixon.txt [[0.30168287]]\n",
      "1977-Carter.txt [[0.70077684]]\n",
      "1981-Reagan.txt [[0.18718071]]\n",
      "1985-Reagan.txt [[0.28179554]]\n",
      "1989-Bush.txt [[0.30575223]]\n",
      "1993-Clinton.txt [[0.17404928]]\n",
      "1997-Clinton.txt [[0.2055027]]\n",
      "2001-Bush.txt [[0.52296753]]\n",
      "2005-Bush.txt [[0.76738999]]\n",
      "2009-Obama.txt [[0.5291141]]\n",
      "2013-Obama.txt [[0.37465501]]\n",
      "2017-Trump.txt [[0.11017946]]\n",
      "\n",
      "the most similar inaugural is:  1941-Roosevelt.txt\n"
     ]
    }
   ],
   "source": [
    "# import library for calculating cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# define counters\n",
    "maxcos = -1\n",
    "maxname = new_df.name.values[0][:-4]\n",
    "# calculate the cosine similarity with all addresses\n",
    "# and find the closes one\n",
    "for i in range(U.shape[0]):\n",
    "    current = np.expand_dims(U[i], axis = 0)\n",
    "    cos = cosine_similarity(current, query_feature)\n",
    "    print(new_df.name.values[i], cos)\n",
    "    if cos > maxcos:\n",
    "        maxcos = cos\n",
    "        maxname = new_df.name.values[i]\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "print('\\nthe most similar inaugural is: ', maxname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On each national day of inauguration since 1789, the people have renewed their sense of dedication to the United States.\\n\\nIn Washington\\'s day the task of the people was to create and weld together a nation.\\n\\nIn Lincoln\\'s day the task of the people was to preserve that Nation from disruption from within.\\n\\nIn this day the task of the people is to save that Nation and its institutions from disruption from without.\\n\\nTo us there has come a time, in the midst of swift happenings, to pause for a moment and take stock -- to recall what our place in history has been, and to rediscover what we are and what we may be. If we do not, we risk the real peril of inaction.\\n\\nLives of nations are determined not by the count of years, but by the lifetime of the human spirit. The life of a man is three-score years and ten: a little more, a little less. The life of a nation is the fullness of the measure of its will to live.\\n\\nThere are men who doubt this. There are men who believe that democracy, as a form of Government and a frame of life, is limited or measured by a kind of mystical and artificial fate that, for some unexplained reason, tyranny and slavery have become the surging wave of the future -- and that freedom is an ebbing tide.\\n\\nBut we Americans know that this is not true.\\n\\nEight years ago, when the life of this Republic seemed frozen by a fatalistic terror, we proved that this is not true. We were in the midst of shock -- but we acted. We acted quickly, boldly, decisively.\\n\\nThese later years have been living years -- fruitful years for the people of this democracy. For they have brought to us greater security and, I hope, a better understanding that life\\'s ideals are to be measured in other than material things.\\n\\nMost vital to our present and our future is this experience of a democracy which successfully survived crisis at home; put away many evil things; built new structures on enduring lines; and, through it all, maintained the fact of its democracy.\\n\\nFor action has been taken within the three-way framework of the Constitution of the United States. The coordinate branches of the Government continue freely to function. The Bill of Rights remains inviolate. The freedom of elections is wholly maintained. Prophets of the downfall of American democracy have seen their dire predictions come to naught.\\n\\nDemocracy is not dying.\\n\\nWe know it because we have seen it revive--and grow.\\n\\nWe know it cannot die -- because it is built on the unhampered initiative of individual men and women joined together in a common enterprise -- an enterprise undertaken and carried through by the free expression of a free majority.\\n\\nWe know it because democracy alone, of all forms of government, enlists the full force of men\\'s enlightened will.\\n\\nWe know it because democracy alone has constructed an unlimited civilization capable of infinite progress in the improvement of human life.\\n\\nWe know it because, if we look below the surface, we sense it still spreading on every continent -- for it is the most humane, the most advanced, and in the end the most unconquerable of all forms of human society.\\n\\nA nation, like a person, has a body--a body that must be fed and clothed and housed, invigorated and rested, in a manner that measures up to the objectives of our time.\\n\\nA nation, like a person, has a mind -- a mind that must be kept informed and alert, that must know itself, that understands the hopes and the needs of its neighbors -- all the other nations that live within the narrowing circle of the world.\\n\\nAnd a nation, like a person, has something deeper, something more permanent, something larger than the sum of all its parts. It is that something which matters most to its future -- which calls forth the most sacred guarding of its present.\\n\\nIt is a thing for which we find it difficult -- even impossible -- to hit upon a single, simple word.\\n\\nAnd yet we all understand what it is -- the spirit -- the faith of America. It is the product of centuries. It was born in the multitudes of those who came from many lands -- some of high degree, but mostly plain people, who sought here, early and late, to find freedom more freely.\\n\\nThe democratic aspiration is no mere recent phase in human history. It is human history. It permeated the ancient life of early peoples. It blazed anew in the middle ages. It was written in Magna Charta.\\n\\nIn the Americas its impact has been irresistible. America has been the New World in all tongues, to all peoples, not because this continent was a new-found land, but because all those who came here believed they could create upon this continent a new life -- a life that should be new in freedom.\\n\\nIts vitality was written into our own Mayflower Compact, into the Declaration of Independence, into the Constitution of the United States, into the Gettysburg Address.\\n\\nThose who first came here to carry out the longings of their spirit, and the millions who followed, and the stock that sprang from them -- all have moved forward constantly and consistently toward an ideal which in itself has gained stature and clarity with each generation.\\n\\nThe hopes of the Republic cannot forever tolerate either undeserved poverty or self-serving wealth.\\n\\nWe know that we still have far to go; that we must more greatly build the security and the opportunity and the knowledge of every citizen, in the measure justified by the resources and the capacity of the land.\\n\\nBut it is not enough to achieve these purposes alone. It is not enough to clothe and feed the body of this Nation, and instruct and inform its mind. For there is also the spirit. And of the three, the greatest is the spirit.\\n\\nWithout the body and the mind, as all men know, the Nation could not live.\\n\\nBut if the spirit of America were killed, even though the Nation\\'s body and mind, constricted in an alien world, lived on, the America we know would have perished.\\n\\nThat spirit -- that faith -- speaks to us in our daily lives in ways often unnoticed, because they seem so obvious. It speaks to us here in the Capital of the Nation. It speaks to us through the processes of governing in the sovereignties of 48 States. It speaks to us in our counties, in our cities, in our towns, and in our villages. It speaks to us from the other nations of the hemisphere, and from those across the seas -- the enslaved, as well as the free. Sometimes we fail to hear or heed these voices of freedom because to us the privilege of our freedom is such an old, old story.\\n\\nThe destiny of America was proclaimed in words of prophecy spoken by our first President in his first inaugural in 1789 -- words almost directed, it would seem, to this year of 1941: \"The preservation of the sacred fire of liberty and the destiny of the republican model of government are justly considered deeply, finally, staked on the experiment intrusted to the hands of the American people.\"\\n\\nIf we lose that sacred fire--if we let it be smothered with doubt and fear -- then we shall reject the destiny which Washington strove so valiantly and so triumphantly to establish. The preservation of the spirit and faith of the Nation does, and will, furnish the highest justification for every sacrifice that we may make in the cause of national defense.\\n\\nIn the face of great perils never before encountered, our strong purpose is to protect and to perpetuate the integrity of democracy.\\n\\nFor this we muster the spirit of America, and the faith of America.\\n\\nWe do not retreat. We are not content to stand still. As Americans, we go forward, in the service of our country, by the will of God.\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the most similar inauguarl\n",
    "inaugural.raw(maxname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
