{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inaugural Similarity Analysis\n",
    "1. Implement TF-IDF from scratch and use it to find the closest historic inaugural address to the 2017 address by President Trump\n",
    "2. Use Latent Symantec Indexing to identify an Inaugural most similar to a user-defined query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import inaugural\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize stemmer and lemmatizer\n",
    "porter    = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "wnl       = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first 4 items of the inaugural datasets\n",
    "inaugural.fileids()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the tokenized words from the first inaugural \n",
    "inaugural.words(inaugural.fileids()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Stopwords\n",
    "\n",
    "**Update stopwords**\n",
    "\n",
    "Remove all punctuation and strange unicode characters, and anything else that might be extraneous. However, the updated list of stopwords is not exaustive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update stopwords\n",
    "stop_words.update(['-', ',', '.', '!', '?', ' ', ':', ';', '/', '[', ']', \n",
    "                   '*', '\"', '(', ')', '#', '$', '%', '&', '~', '@', '<', '>',\n",
    "                  '{', '}', '^', '--', \"'\", '.\"', '14th', '\";', '\"?', '),', '...', \n",
    "                   '¡¦', '¡§', '¡¨¡', ',\"', '.)', '....', '\\x80\\x94', '¡', '.¡¨'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Read each inaugural address into an Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Create a vocabulary as a set of all unique stemmed terms in the corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an empty set to store vocabs\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code for creating the vocab goes here\n",
    "temp_list = [wnl.lemmatize(porter.stem(w.lower())) for w in inaugural.words() if w.lower() not in stop_words]\n",
    "vocab = set(sorted(temp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  5399  unique words in our corpus.\n"
     ]
    }
   ],
   "source": [
    "# check out vocab length\n",
    "print('there are ', len(vocab), ' unique words in our corpus.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Use ocabulary to read each inaugural address into a dataframe**\n",
    "\n",
    "Each row of the dataframe represents a document (one of the addresses), each column of the dataframe is a term from the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 5399)\n"
     ]
    }
   ],
   "source": [
    "# initiate a dictionary for tracking document size\n",
    "doc_length = {}\n",
    "# initiate an empty dataframe\n",
    "df = pd.DataFrame()\n",
    "# loop through all documents in corpus\n",
    "for fileid in inaugural.fileids():\n",
    "    # populate doc_length\n",
    "    doc_length[fileid] = len(inaugural.words(fileid))\n",
    "    # create a temporary dictionary for each document for tracking word frequency\n",
    "    temp_list = [wnl.lemmatize(porter.stem(w.lower())) for w in inaugural.words(fileid) \n",
    "                 if w.lower() not in stop_words]\n",
    "    temp_dict = dict(FreqDist(sorted(temp_list)))\n",
    "    # covert dictionary to series and add to dataframe\n",
    "    df = df.append(pd.Series(temp_dict, name = fileid))\n",
    "    pass\n",
    "# fill null value\n",
    "df.fillna(0, inplace = True)\n",
    "# check df size\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Compute TF-IDF for the document-term matrix ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1. Write a function to compute term frequency (TF) for each document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute term frequency\n",
    "# inputs: wordvec is a series that contains, for a given doc, \n",
    "#                 the word counts for each term in the vocab\n",
    "#         doclen  is the length of the document\n",
    "# returns: a series with new term-frequencies (raw counts divided by doc length)\n",
    "def computetf(wordvec,doclen):\n",
    "    return wordvec/doclen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Write a function to comput inverse document frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# input:   document-by-term (row-by-column) dataframe\n",
    "# returns: dictionary of key-value pairs. Keys are terms in the vocab, values are IDF.\n",
    "def computeidf(df):\n",
    "    idf_dict = {}\n",
    "    for vocab in df.columns.values:\n",
    "        # calculate the ratio of total number of documents over number of documents\n",
    "        # containing current vocab, and tkae a log of this ratio.\n",
    "        ratio = df.shape[0] / (df[vocab] > 0).sum()\n",
    "        idf_dict[vocab] = math.log(ratio)\n",
    "        pass\n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a new dataframe and populate it with the TF-IDF values for each document-term combination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a new dataframe that stores TF-IDF values\n",
    "newdf = pd.DataFrame()\n",
    "# compute idf\n",
    "idfdict = computeidf(df)\n",
    "# compute tf-idf\n",
    "cols = df.columns\n",
    "for index, row in df.iterrows():\n",
    "    newrow = computetf(row,doc_length[index])\n",
    "    for c in cols:\n",
    "        newrow[c] = newrow[c]*idfdict[c]\n",
    "    newdf = newdf.append(newrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (58, 5399)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of tf-idf dataframe\n",
    "print('shape: ', newdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>1</th>\n",
       "      <th>100</th>\n",
       "      <th>120</th>\n",
       "      <th>125</th>\n",
       "      <th>13</th>\n",
       "      <th>15th</th>\n",
       "      <th>16</th>\n",
       "      <th>1774</th>\n",
       "      <th>1776</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>yorktown</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealou</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789-Washington.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793-Washington.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797-Adams.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801-Jefferson.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805-Jefferson.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     000    1  100  120  125   13  15th   16  1774  1776  ...  \\\n",
       "1789-Washington.txt  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0   0.0  ...   \n",
       "1793-Washington.txt  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0   0.0  ...   \n",
       "1797-Adams.txt       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0   0.0  ...   \n",
       "1801-Jefferson.txt   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0   0.0  ...   \n",
       "1805-Jefferson.txt   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0   0.0  ...   \n",
       "\n",
       "                     york  yorktown  young  younger  youngest  youth  \\\n",
       "1789-Washington.txt   0.0       0.0    0.0      0.0       0.0    0.0   \n",
       "1793-Washington.txt   0.0       0.0    0.0      0.0       0.0    0.0   \n",
       "1797-Adams.txt        0.0       0.0    0.0      0.0       0.0    0.0   \n",
       "1801-Jefferson.txt    0.0       0.0    0.0      0.0       0.0    0.0   \n",
       "1805-Jefferson.txt    0.0       0.0    0.0      0.0       0.0    0.0   \n",
       "\n",
       "                         zeal  zealou  zealous  zone  \n",
       "1789-Washington.txt  0.000000     0.0      0.0   0.0  \n",
       "1793-Washington.txt  0.000000     0.0      0.0   0.0  \n",
       "1797-Adams.txt       0.000766     0.0      0.0   0.0  \n",
       "1801-Jefferson.txt   0.001024     0.0      0.0   0.0  \n",
       "1805-Jefferson.txt   0.002493     0.0      0.0   0.0  \n",
       "\n",
       "[5 rows x 5399 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the first 5 rows of the tf-idf dataframe\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. Using TF-IDF values, find and rank order the 3 closest inaugural addresses to Donald Trump's 2017 address, measured by cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000        0.0\n",
       "1          0.0\n",
       "100        0.0\n",
       "120        0.0\n",
       "125        0.0\n",
       "          ... \n",
       "youth      0.0\n",
       "zeal       0.0\n",
       "zealou     0.0\n",
       "zealous    0.0\n",
       "zone       0.0\n",
       "Name: 2017-Trump.txt, Length: 5399, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# President Trump's address is 57 (0-indexed)\n",
    "newdf.iloc[57,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 Create an array called dist that contains the cosine similarity distance between the 2017 inaugural address and each of the inaugural addresses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# assign PResident Trump's tf_idf values to d1\n",
    "d1 = newdf.iloc[57,:]\n",
    "# find its magnitude \n",
    "norm_d1 = np.sqrt(np.sum(np.square(d1)))\n",
    "# create a list for storing cosine similarities between each inaugural and President Trump\n",
    "dist = []\n",
    "for index,row in newdf.iterrows():\n",
    "    temp_norm = np.sqrt(np.sum(np.square(row)))\n",
    "    cos_sim = np.dot(d1, row) / (norm_d1 * temp_norm)\n",
    "    dist.append(cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Find the 3 closest associated inaugural address, when measured by cosign similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1969-Nixon.txt', '1997-Clinton.txt', '1993-Clinton.txt'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find 3 inaugurals that are most similar to Trump. \n",
    "indices = np.array(dist).argsort()[-4:-1]\n",
    "df.index[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity is often used in text classification to measure the textual content similarity of two documents. This is normally calculated based on word frequencies relative to the entire corpus, which can be meaninfully represented using TF-IDF.\n",
    "\n",
    "In this case, inaugural A is considered 'close' to inaugural B if the words used and frequencies of each word used are relatively similar than the ones between inaugural A and inaugural B. As illustrated in the code snippets below, the first dataframe dipicts the words that appeared more than 5 times in Trump's inaugural and also appeared at least once in the 3 closest associated inaugural address. We could see that these words such as 'america', 'great', 'people', 'nation' were also frequently used by the other 3 presidents.\n",
    "\n",
    "In contrast, the second dataframe shows the 3 furtherest assocaited inaugural address, where such pattern is pattern is not observed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>american</th>\n",
       "      <th>great</th>\n",
       "      <th>nation</th>\n",
       "      <th>new</th>\n",
       "      <th>one</th>\n",
       "      <th>peopl</th>\n",
       "      <th>presid</th>\n",
       "      <th>world</th>\n",
       "      <th>america</th>\n",
       "      <th>make</th>\n",
       "      <th>god</th>\n",
       "      <th>across</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1969-Nixon.txt</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-Clinton.txt</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-Clinton.txt</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-Trump.txt</th>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  american  great  nation   new   one  peopl  presid  world  \\\n",
       "1969-Nixon.txt         4.0    7.0     9.0   8.0   7.0   15.0     3.0   15.0   \n",
       "1997-Clinton.txt      16.0    6.0    15.0  29.0  10.0   11.0     1.0   15.0   \n",
       "1993-Clinton.txt      14.0    2.0     5.0   9.0   1.0   12.0     3.0   20.0   \n",
       "2017-Trump.txt        15.0    6.0    13.0   6.0   9.0   10.0     5.0    6.0   \n",
       "\n",
       "                  america  make  god  across  today  \n",
       "1969-Nixon.txt        6.0  10.0  6.0     1.0    5.0  \n",
       "1997-Clinton.txt     15.0   5.0  1.0     2.0    6.0  \n",
       "1993-Clinton.txt     19.0   3.0  2.0     4.0   10.0  \n",
       "2017-Trump.txt       20.0   6.0  5.0     5.0    5.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find words that appear in all 4 inaugurals and appears at least 5 times in Trump's inaugural\n",
    "similar_df = df.loc[['1969-Nixon.txt', '1997-Clinton.txt', '1993-Clinton.txt', '2017-Trump.txt'], :]\n",
    "keywords = [w for w in similar_df.columns if (similar_df[w]>0).sum() >= 4 and similar_df.loc['2017-Trump.txt', w] >= 5]\n",
    "similar_df[keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1789-Washington.txt', '1809-Madison.txt', '1829-Jackson.txt'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find 3 inaugurals that are most different from Trump. \n",
    "df.index[np.array(dist).argsort()[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countri</th>\n",
       "      <th>everi</th>\n",
       "      <th>nation</th>\n",
       "      <th>never</th>\n",
       "      <th>peopl</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789-Washington.txt</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809-Madison.txt</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829-Jackson.txt</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-Trump.txt</th>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     countri  everi  nation  never  peopl  right\n",
       "1789-Washington.txt      5.0    9.0     4.0    2.0    4.0    2.0\n",
       "1809-Madison.txt         5.0    2.0    10.0    1.0    1.0    5.0\n",
       "1829-Jackson.txt         2.0    1.0     6.0    1.0    4.0    4.0\n",
       "2017-Trump.txt          12.0    7.0    13.0    6.0   10.0    5.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find words that appear in all 4 inaugurals and appears at least 5 times in Trump's inaugural\n",
    "diff_df = df.loc[['1789-Washington.txt', '1809-Madison.txt', '1829-Jackson.txt', '2017-Trump.txt'], :]\n",
    "keywords = [w for w in diff_df.columns if (diff_df[w]>0).sum() >= 4 and diff_df.loc['2017-Trump.txt', w] >= 5]\n",
    "diff_df[keywords]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
